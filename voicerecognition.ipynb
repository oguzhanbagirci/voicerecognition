{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee16f576",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.data API\n",
    "data = pathlib.Path(r'C:\\\\Users\\\\Oguzhan\\\\PythonProjects\\\\Kiosk Proje\\\\speech')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b049870b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking basic statistics about the dataset\n",
    "words = np.array(tf.io.gfile.listdir(str(data)))\n",
    "words = words[words != '.DS_Store']\n",
    "print('Words:', words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ed4dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ses dosyalarını bir listeye çıkarıp birleştirmek\n",
    "filenames = tf.io.gfile.glob(str(data) + '//')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "num_samples = len(filenames)\n",
    "print(num_samples)\n",
    "#toplam 26042 örnek ve  label başına xxxx örnek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe282971",
   "metadata": {},
   "outputs": [],
   "source": [
    "#80:10:10 bölmek (eğitim, doğrulama,test)\n",
    "train_files = filenames[:15626]\n",
    "val_files = filenames[15625: 15624 + 5208]\n",
    "test_files = filenames[-5208:]\n",
    "\n",
    "print('train size:',len(train_files))\n",
    "print('val size:',len(val_files))\n",
    "print('test size:',len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334a4f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ses dosyasını sayısal bir tensöre dönüştürmeliyiz\n",
    "#wav kodlu sesi , tensör ve örnekleme hızı olarak döndüren tf.audio.decode_wav'ı kullanabiliriz. => değerleri [-1.0,1.0] aralığında normalleştirir.\n",
    "def decode_audio(audio_binary):\n",
    "  audio, _ =tf.audio.decode_wav(audio_binary)\n",
    "  return tf.squeeze(audio, axis = -1)\n",
    "  \n",
    "\n",
    "\n",
    "# #tf.squeeze: Given a tensor input, this operation returns a tensor of the same type with all dimensions of size 1 removed. If you don't want to remove all size 1 dimensions, you can remove specific size 1 dimensions by specifying axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5649850",
   "metadata": {},
   "outputs": [],
   "source": [
    "#her wav dosyasının etiketi, üst dizinidir\n",
    "def get_label(file_path):\n",
    "  parts = tf.strings.split(file_path, os.path.sep)\n",
    "  #Not: Bunun bir TensorFlow grafiğinde çalışmasını sağlamak için tuple paketini açmak yerine burada indekslemeyi kullan\n",
    "  return parts[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d624f29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#denetimli eğitim için ses ve etiketleri içeren bir demet çıktısını alacak yöntem\n",
    "def get_wave_and_label(file_path):\n",
    "  label = get_label(file_path)\n",
    "  audio_binary = tf.io.read_file(file_path)\n",
    "  waveform = decode_audio(audio_binary)\n",
    "  return waveform,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b017698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ses etiketi çiftlerini çıkarmak, sonuçları kontrol etmek, eğitim setini oluşturmak için\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(train_files)\n",
    "waveform_ds = files_ds.map(get_wave_and_label, num_parallel_calls = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85f04f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 3\n",
    "cols = 3\n",
    "n = rows*cols \n",
    "fig, axes =plt.subplots(rows,cols, figsize=(10,12))\n",
    "for i,(audio,label) in enumerate(waveform_ds.take(9)):\n",
    "  r = i // cols\n",
    "  c = i % cols\n",
    "  ax = axes[r][c]\n",
    "  ax.plot(audio.numpy())\n",
    "  ax.set_yticks(np.arange(-1.2, 1.2, 0.2))\n",
    "  label = label.numpy().decode('utf-8')\n",
    "  ax.set_title(label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48942642",
   "metadata": {},
   "source": [
    "# #Dalga biçimini, zaman içindeki frekans değişikliklerini gösteren ve 2B görüntü olarak temsil edilebilen bir spektrograma dönüştüreceksiniz. Bu, sesi zaman frekans alanına dönüştürmek için kısa süreli Fourier dönüşümü (STFT) uygulanarak yapılabilir.Bir Fourier dönüşümü ( tf.signal.fft ) bir sinyali bileşen frekanslarına dönüştürür, ancak tüm zaman bilgilerini kaybeder. STFT ( tf.signal.stft ) sinyali zaman pencerelerine böler ve her pencerede bir Fourier dönüşümü çalıştırır, bazı zaman bilgilerini korur ve üzerinde standart konvolüsyonlar çalıştırabileceğiniz bir 2D tensör döndürür.STFT, büyüklüğü ve fazı temsil eden bir dizi karmaşık sayı üretir. Ancak, bu öğretici için yalnızca, tf.abs çıktısına tf.abs uygulanarak elde edilebilecek büyüklüğe ihtiyacınız tf.signal.stft .\n",
    "# \n",
    "# frame_length ve frame_step parametrelerini, oluşturulan spektrogram \"görüntü\" hemen hemen kare olacak şekilde seçin.Ayrıca dalga formlarının aynı uzunlukta olmasını istersiniz, böylece onu bir spektrogram görüntüsüne dönüştürdüğünüzde, sonuçlar benzer boyutlara sahip olacaktır. Bu, bir saniyeden daha kısa olan ses kliplerini basitçe sıfır doldurarak yapılabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b6668d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectogram(waveform):\n",
    "  #16000' den az sayıda örnek içeren dosyalar için padding\n",
    "  zero_padding = tf.zeros([16000]-tf.shape(waveform), dtype = tf.float32)\n",
    "  #sesleri padding ile birleştir böylece tüm ses klipleri aynı uzunlukta olacaktır\n",
    "  waveform = tf.cast(waveform, tf.float32)\n",
    "  equal_length = tf.concat([waveform, zero_padding], 0)\n",
    "  #abs metoduna verebilmek için stft metodundan geşirdik\n",
    "  spectogram = tf.signal.stft(equal_length,frame_length=255, frame_step = 128)\n",
    "  spectogram = tf.abs(spectogram)\n",
    "  return spectogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcba5b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#veri kümesinden bir örneğin dalga biçimini, spektogramını ve gerçek sesini karşılaştıralım\n",
    "for waveform,label in waveform_ds.take(1):\n",
    "  label = label.numpy().decode('utf-8')\n",
    "  spectogram = get_spectogram(waveform)\n",
    "\n",
    "  print('label:',label)\n",
    "  print('waveform shape:', waveform.shape)\n",
    "  print('spectogram shape:',spectogram.shape)\n",
    "  print('play audio')\n",
    "  display.display(display.Audio(waveform, rate = 16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809be21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#waveform ve spectogramı grafiksel olarak göstermek\n",
    "def plot_spectogram(spectogram, ax):\n",
    "  #zamanın x ekseninde temsil edilmesi için frekansları log ölçeğine dönüştürün ve aktarın\n",
    "  log_spec = np.log(spectogram.T)\n",
    "  height = log_spec.shape[0]\n",
    "  #belirli bir aralıkta eşit aralıklı değerleri döndür\n",
    "  X = np.arange(16000, step = height+1)\n",
    "  Y = range(height)\n",
    "  #Create a pseudocolor plot with a non-regular rectangular grid.\n",
    "  ax.pcolormesh(X,Y,log_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dca9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(2, figsize=(12,8))\n",
    "timescale = np.arange(waveform.shape[0])\n",
    "axes[0].plot(timescale, waveform.numpy())\n",
    "axes[0].set_title('Waveform')\n",
    "axes[0].set_xlim([0,16000])\n",
    "plot_spectogram(spectogram.numpy(), axes[1])\n",
    "axes[1].set_title('Spectogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56215b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dalga formu veri setinin spektogram görüntülerine karşılık gelen etiketlerine tamsayı kimlikler atalım\n",
    "def get_spectogram_and_label_id(audio,label):\n",
    "  spectogram = get_spectogram(audio)\n",
    "  spectogram = tf.expand_dims(spectogram, -1)\n",
    "  #Returns the index with the largest value across axes of a tensor\n",
    "  label_id = tf.argmax(label == words)\n",
    "  return spectogram, label_id\n",
    "\n",
    "spectogram_ds = waveform_ds.map(get_spectogram_and_label_id, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d82834",
   "metadata": {},
   "outputs": [],
   "source": [
    "#veri kümesinin farklı örnekleri için spektogram görüntülerini inceleme\n",
    "rows = 3\n",
    "cols = 3\n",
    "n = rows * cols\n",
    "fig,axes = plt.subplots(rows,cols,figsize = (10,10))\n",
    "for i, (spectogram, label_id) in enumerate(spectogram_ds.take(n)):\n",
    "  r = i//cols\n",
    "  c = i % cols\n",
    "  ax = axes[r][c]\n",
    "  plot_spectogram(np.squeeze(spectogram.numpy()),ax)\n",
    "  ax.set_title(words[label_id.numpy()])\n",
    "  ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5d6186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modeli eğitmeden önce doğrulama ve test setlerinde eğitim seti ön işlemesini tekrarlamalıyız\n",
    "def preprocess_dataset(files):\n",
    "  files_ds = tf.data.Dataset.from_tensor_slices(files)\n",
    "  output_ds = files_ds.map(get_wave_and_label, num_parallel_calls=AUTOTUNE)\n",
    "  output_ds = output_ds.map(get_spectogram_and_label_id, num_parallel_calls = AUTOTUNE)\n",
    "  return output_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8069633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = spectogram_ds\n",
    "val_ds = preprocess_dataset(val_files)\n",
    "test_ds = preprocess_dataset(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815c4e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modeli eğitmek için eğitim ve doğrulama setlerini gruplama\n",
    "train_ds = train_ds.batch(batch_size=64)\n",
    "val_ds = val_ds.batch(batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f87a7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modeli eğitirken okuma gecikmesini azaltmak için cache() ve prefetch() işlemi uygula\n",
    "train_ds = train_ds.cache().prefetch(AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d47ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for spectogram, _ in spectogram_ds.take(1):\n",
    "  input_shape = spectogram.shape\n",
    "print('Input shape:', input_shape)\n",
    "num_labels = len(words) \n",
    "\n",
    "norm_layer = preprocessing.Normalization()\n",
    "norm_layer.adapt(spectogram_ds.map(lambda x, _:x))\n",
    "\n",
    "model = models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        preprocessing.Resizing(32,32),\n",
    "        norm_layer,\n",
    "        layers.Conv2D(32,3, activation = 'relu'),\n",
    "        #layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64,3,activation = 'relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation = 'relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_labels)\n",
    "])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50fc15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca60bdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds,validation_data=val_ds,epochs=8,callbacks=tf.keras.callbacks.EarlyStopping(verbose=0,patience=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7693e71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Capstone.h5\")\n",
    "from tensorflow.keras.models import load_model\n",
    "new_model = load_model('Capstone.h5')\n",
    "new_model.summary()\n",
    "new_model.get_weights()\n",
    "new_model.optimizer\n",
    "#Convert to .h5 file to .tflite file\n",
    "model = tf.keras.models.load_model('C:\\\\Users\\\\Alperen\\\\PythonProjects\\\\Kiosk Proje\\\\Capstone.h5')\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "open(\"Capstone.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d805fb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eğitim ve doğrulama kaybı eğrileri\n",
    "metrics = history.history\n",
    "plt.plot(history.epoch, metrics['loss'],metrics['val_loss'])\n",
    "plt.legend(['loss','val_loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528c8e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modeli test seti üzerinde çalıştırıp,performansı kontrol etme\n",
    "test_audio = []\n",
    "test_labels=[]\n",
    "for audio,label in test_ds:\n",
    "  test_audio.append(audio.numpy())\n",
    "  test_labels.append(label.numpy())\n",
    "\n",
    "test_audio = np.array(test_audio)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "y_pred = np.argmax(model.predict(test_audio),axis=1)\n",
    "y_true = test_labels\n",
    "test_acc = sum(y_pred == y_true) / len(y_true)\n",
    "print(f'Test accuracy: {test_acc:.0%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25779b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#karışıklık matrisi => modelin test setindeki komutların her birindeki başarısını gösterir\n",
    "confusion_mtx = tf.math.confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10,8))\n",
    "sb.heatmap(confusion_mtx, xticklabels=words, yticklabels=words, annot=True, fmt='g')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5c69b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs=16000\n",
    "duration = 1  # seconds\n",
    "filename = 'record.wav'\n",
    "print(\"Recording Audio...\")\n",
    "myrecording = sd.rec(duration * fs , samplerate=fs, channels=1,dtype='float64')\n",
    "sd.wait()\n",
    "sf.write(filename, myrecording, fs)\n",
    "print(\"Audio recording complete\")\n",
    "\n",
    "samples, fs = librosa.load('record.wav',sr=44100)\n",
    "ipd.Audio(samples,rate=44100)\n",
    "\n",
    "data_way = pathlib.Path('C:\\\\Users\\\\Alperen\\\\PythonProjects\\\\Kiosk Proje')\n",
    "sample_file = data_way/'record.wav' #gürültülü seslerle sorunsuz çalışıyor\n",
    "sample_ds = preprocess_dataset([str(sample_file)])\n",
    "for spectogram,label in sample_ds.batch(1):\n",
    "    prediction = model(spectogram)\n",
    "    plt.figure(figsize=(11,7))\n",
    "    plt.bar(words,tf.nn.softmax(prediction[0]))\n",
    "    plt.title(f'Prediction for \"{words[label[0]]}\"')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "print(label[0])\n",
    "print('*******')\n",
    "print(words,prediction[0])\n",
    "maxElement = np.amax(prediction)\n",
    "print(str(maxElement))\n",
    "##location = prediction.tf.where(maxElement)\n",
    "##print(location)\n",
    "\n",
    "f = open(\"words.txt\",\"w+\")\n",
    "f.write(str(filename))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
